#!/usr/bin/python
import os
from datetime import datetime
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
import tensorflow as tf
from os import path
from sys import argv
from Model import MCModel
from Logger import debug, error, info

def dataset_load(dirpath):
    forward_path = path.join(dirpath, 'training')
    training_path = path.join(forward_path, 'train')
    validation_path = path.join(forward_path, 'val')
    test_path = path.join(dirpath, 'test')
    if path.isdir(training_path) is True and path.isdir(validation_path) is True and path.isdir(test_path):
        debug("Assets path confirmed: \n\t{}\n\t{}\n\t{}".format(forward_path, validation_path, test_path))
        
        train_IDG = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)# Fattore moltiplicativo per normalizzare i valori dei pixel in GS
        validation_IDG = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)
        test_IDG = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)

        train_dataset = train_IDG.flow_from_directory(batch_size=20, directory=training_path, target_size=(150, 150), class_mode='categorical')
        validation_dataset = validation_IDG.flow_from_directory(batch_size=20, directory=validation_path, target_size=(150, 150), class_mode='categorical')
        test_dataset = test_IDG.flow_from_directory(batch_size=20, directory=test_path, target_size=(150, 150), class_mode='categorical')

        debug("Datasets correctly loaded")
        return (train_dataset, validation_dataset, test_dataset)
    else:
        return (None, None, None)

def help(name):
    error("usage: {} <dataset_path>".format(name))
    exit()

def TB_hooks():
    log_dir = "/tmp/logs/fit/" + datetime.now().strftime("%Y%m%d-%H%M%S")
    return (log_dir, tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1))

def save_hook(weights_path):
    return tf.keras.callbacks.ModelCheckpoint(weights_path, 'accuracy', save_best_only=True, save_weights_only=True, mode='max')

#######################################################

if __name__ == '__main__':
    help(argv[0]) if len(argv) < 2 else None
    (training_ds, validation_ds, test_ds) = dataset_load(argv[1])
    if (training_ds, validation_ds, test_ds) == (None, None, None):
        error('Error in datasets loading: check if the paths are correct!')
        exit()
    
    weights_path = './weights_result'
    training_model = MCModel(training_ds.num_classes, 150, 1)
    
    (TB_logs_dir, TB_callback) = TB_hooks()
    checkpoint_callback = save_hook(weights_path)


    if os.path.exists('{}.index'.format(weights_path)):
        debug('weights file exists at {}'.format(weights_path))
        try:
            training_model.load_weights(weights_path)
            training_model.compile(optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.CategoricalCrossentropy(), metrics=['accuracy'])
        except Exception as ex:
            error('error during weights loading: {}'.format(ex))
            exit()
    else:
        debug('weights file does not exist => the network needs to be trained')
        training_model.compile(optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.CategoricalCrossentropy(), metrics=['accuracy'])
        info('Start training:')
        training_model.fit(training_ds, validation_data=validation_ds, verbose=1, batch_size=20, epochs=10, callbacks=[TB_callback, checkpoint_callback])
    info('Model summary:')
    training_model.summary()
    info('Performance evaluation:')
    results = training_model.evaluate(test_ds, verbose=1)
    info('Results: \n\tLoss => {}\n\t Accuracy => {:5.2f}%'.format(results[0], results[1] * 100))