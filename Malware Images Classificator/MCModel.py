#!/usr/bin/python
import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
import tensorflow as tf
from os import path
from sys import argv

class MCModel(tf.keras.Model):
    def __init__(self, num_classes, img_size, channels):
        super(MCModel, self).__init__()
        # Variables
        self.num_classes = num_classes
        self.img_size = img_size
        self.channels = channels
        self.trained = False

        # Loss function and Optimizer
        self.loss_fun = tf.keras.losses.CategoricalCrossentropy()
        self.optimizer = tf.keras.optimizers.Adam()

        # Metrics
        #self.train_loss = tf.keras.metrics.Mean('train_loss')
        #self.train_accuracy = tf.keras.metrics.CategoricalAccuracy('train_accuracy')
        #self.test_loss = tf.keras.metrics.Mean('test_loss')
        #self.test_accuracy = tf.keras.metrics.CategoricalAccuracy('test_accuracy')

        #Model Layers
        self.layer_input = tf.keras.layers.InputLayer(input_shape=(self.img_size, self.img_size, self.channels))
        self.layer_conv1 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu')
        self.layer_maxpooling1 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))
        self.layer_conv2 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu')
        self.layer_maxpooling2 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))
        self.layer_flatten = tf.keras.layers.Flatten()
        self.layer_dense1 = tf.keras.layers.Dense(128, activation='relu')
        self.layer_dropout = tf.keras.layers.Dropout(0.4)
        self.layer_dense2 = tf.keras.layers.Dense(7, activation='softmax')

    def call(self, x, training=None):
        x = self.layer_input(x)
        x = self.layer_conv1(x)
        x = self.layer_maxpooling1(x)
        x = self.layer_conv2(x)
        x = self.layer_maxpooling2(x)
        x = self.layer_flatten(x)
        x = self.layer_dense1(x)
        x = self.layer_dropout(x, training=training)
        return self.layer_dense2(x)

def dataset_load(dirpath):
    forward_path = path.join(dirpath, 'training')
    training_path = path.join(forward_path, 'train')
    validation_path = path.join(forward_path, 'val')
    test_path = path.join(dirpath, 'test')
    if path.isdir(training_path) is True and path.isdir(validation_path) is True and path.isdir(test_path):
        print("Assets path confirmed: \n\t{}\n\t{}\n\t{}".format(forward_path, validation_path, test_path))
        
        train_IDG = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)# Fattore moltiplicativo per normalizzare i valori dei pixel in GS
        validation_IDG = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)
        test_IDG = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)

        train_dataset = train_IDG.flow_from_directory(batch_size=20, directory=training_path, target_size=(150, 150), class_mode='categorical')
        validation_dataset = validation_IDG.flow_from_directory(batch_size=20, directory=validation_path, target_size=(150, 150), class_mode='categorical')
        test_dataset = test_IDG.flow_from_directory(batch_size=20, directory=test_path, target_size=(150, 150), class_mode='categorical')

        print("Datasets correctly loaded")
        return (train_dataset, validation_dataset, test_dataset)
    else:
        return (None, None, None)

def help(name):
    print("usage: {} <dataset_path>".format(name))
    exit()

if __name__ == '__main__':
    help(argv[0]) if len(argv) < 2 else None
    (training_ds, validation_ds, test_ds) = dataset_load(argv[1])
    if (training_ds, validation_ds, test_ds) == (None, None, None):
        print('Error in datasets loading: check if the paths are correct!')
        exit()
    
    training_model = MCModel(training_ds.num_classes, 150, 1)
    training_model.compile(optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.CategoricalCrossentropy(), metrics=['accuracy'])
    print('Start training:')
    training_model.fit(training_ds, validation_data=validation_ds, verbose=1, batch_size=20, epochs=20)
    print('Model summary:')
    training_model.summary()
    print('Performance evaluation:')
    results = training_model.evaluate(test_ds, verbose=1)
    print('Results: {}'.format(results))#\n\tLoss => {}\n\t Accuracy => {}'.format(results))

    #print(validation_ds.num_classes)
